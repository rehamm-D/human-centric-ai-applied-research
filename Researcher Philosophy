# Researcher Area Of Interest -
Human-Centric AI Case Study: Emotional Intelligence and Learner Engagement in Duolingo — 
(Rebuilding Emotional Trust in Language Learning)

Author’s Design Philosophy: “AI must be used to fill the void humans aren’t available to - emotional belonging — 
rather than replacing humans.

Author: Tanisha Hasan Shaikh (B.Tech Grad & Independent Researcher) 
Discipline: Software Engineering | Human-Centric AI | Digital Product Research 
Context: Independent Product & Behavioral Analysis
Platform: Duolingo
Year: 2025

## Orientation
My research philosophy is grounded in **self-driven inquiry, prolonged observation, and human-centered system thinking**. I approach research not as a pursuit of novelty alone, but as a responsibility to understand how technology is emotionally received, interpreted, and lived with by humans over time.

This philosophy emerged from an independent, longitudinal study conducted over **five months (150+ days)**, driven by curiosity, discipline, and a need to examine gaps between system metrics and human experience.

---

## Self-Driven and Draft-Led Inquiry
This research was not initiated through institutional funding, payroll, or contractual obligation. It was **self-initiated**, guided by a personally authored draft that evolved through observation, reflection, and iterative refinement.

Working independently required:
- defining the research scope without external framing
- validating insights through sustained engagement rather than short experiments
- maintaining methodological discipline without formal oversight

The absence of imposed structure allowed deeper attention to **behavioral nuance, emotional signals, and long-term patterns** often overlooked in short-cycle studies.

---

## Commitment to Longitudinal Depth
I believe meaningful insights into human–AI interaction require time. Short-term usage captures novelty; long-term usage reveals truth.

Over five months of continuous engagement, I observed:
- how confidence plateaus form
- how silence becomes normalized
- how motivation shifts once external rewards lose novelty
- how emotional trust builds—or erodes—over time

This duration was essential to move beyond surface engagement metrics and understand **expressive behavior as a lived process**, not a feature outcome.

---

## Why Human-Centric AI
Human-centric AI, to me, is not an aesthetic preference—it is a **design obligation**.

Systems that optimize for accuracy, speed, or engagement alone risk ignoring:
- emotional hesitation
- fear of judgment
- cultural constraints
- identity formation

My research centers on the belief that **confidence, trust, and expressive courage are first-class system outcomes**, not side effects. AI systems should act not only as instructors or evaluators, but as **emotionally aware participants** in the learning journey.

---

## Identity, Emotion, and Expression
A recurring insight in my work is that **identity shapes behavior more than instruction**.

Learners act in alignment with how systems see them:
- metrics produce performers
- scores produce comparison
- identity produces ownership

This belief informed the development of identity constructs such as *DUO-SETTER*, where recognition is tied to courage and consistency rather than correctness. I view identity-aware design as a powerful, ethical lever for long-term engagement.

---

## Research as Responsibility
I approach research with the understanding that AI systems influence not just outcomes, but self-perception. This carries responsibility.

My philosophy emphasizes:
- minimizing emotional harm
- avoiding performative pressure
- respecting cultural differences
- designing encouragement without manipulation

Growth should emerge from **authentic confidence**, not engineered visibility.

---

## Positioning
I position myself as an **applied human-centric AI researcher** working at the intersection of:
- behavioral observation
- system design
- emotional intelligence
- global user experience

My work bridges research and real-world systems, aiming to inform how scalable AI products can remain humane, inclusive, and emotionally aware.

---

## Closing Reflection
This research reinforced a central belief:  
**Technology does not merely teach skills — it shapes how humans feel about using their voice.**

My philosophy is to build, study, and document AI systems that honor that responsibility.
