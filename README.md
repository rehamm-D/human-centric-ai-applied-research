# Human-Centric AI — Independent Research Case Study by Tanisha Hasan 

> **Independent Research | Applied AI Systems | Ethics-by-Design**

This repository documents an end-to-end **human-centric AI research study**, covering theory, design principles, system architecture, experimentation, evaluation, ethics, limitations, and future work. The study focuses on building AI systems that are **useful, usable, trustworthy, inclusive, and accountable**.

---

## 1. Abstract

Human-centric AI (HCAI) emphasizes aligning artificial intelligence with human values, needs, and capabilities. This independent research investigates how human-centered principles can be embedded across the AI lifecycle—from problem framing and data collection to model design, evaluation, deployment, and governance. The study combines literature synthesis, system prototyping, user-centered evaluation, and ethical risk analysis.

---

## 2. Keywords

Human-Centric AI, Responsible AI, Explainable AI, Trustworthy AI, Human-in-the-Loop, AI Ethics, UX for AI, Fairness, Transparency, Accountability

---

## 3. Research Motivation & Problem Statement

### 3.1 Motivation

Most AI systems optimize for accuracy or efficiency while overlooking human factors such as trust, interpretability, usability, and social impact. This gap leads to systems that are technically strong but **humanly misaligned**.

### 3.2 Problem Statement

How can AI systems be designed and evaluated such that:

* Humans remain meaningfully in control
* Decisions are understandable and contestable
* Outcomes are fair across diverse user groups
* Systems inspire trust without over-reliance

---

## 4. Research Objectives

* Define a **human-centric AI framework** applicable to real-world systems
* Design a prototype AI system guided by HCAI principles
* Evaluate the system using **human-centered metrics** (trust, usability, transparency)
* Identify ethical risks and mitigation strategies
* Propose a reproducible research methodology

---

## 5. Literature Review

### 5.1 Evolution of Human-Centric AI

* Human–Computer Interaction (HCI)
* Value-Sensitive Design
* Responsible & Trustworthy AI

### 5.2 Core Theoretical Foundations

* Human-in-the-Loop Systems
* Sociotechnical Systems Theory
* Cognitive Load & Decision Support

### 5.3 Gaps in Existing Research

* Over-focus on accuracy
* Limited user-centered evaluation
* Weak deployment-stage governance

---

## 6. Human-Centric AI Principles

### 6.1 Human Agency & Oversight

* AI as decision-support, not decision-replacement
* Override and appeal mechanisms

### 6.2 Transparency & Explainability

* Model-level explanations
* Decision-level explanations
* User-adaptive explanation depth

### 6.3 Fairness & Inclusivity

* Bias-aware data practices
* Fairness metrics across demographics

### 6.4 Accountability & Governance

* Audit trails
* Responsibility assignment

### 6.5 Privacy & Data Dignity

* Data minimization
* Consent-aware pipelines

---

## 7. Research Methodology

### 7.1 Study Design

* Mixed-methods approach
* Qualitative + Quantitative analysis

### 7.2 Data Sources

* Synthetic datasets
* Public benchmark datasets
* User-generated interaction logs

### 7.3 Tools & Stack

* Python, Jupyter
* ML frameworks
* UX testing tools

---

## 8. System Architecture (Prototype)

### 8.1 Overview

A human-centric conversational AI system designed for **supportive, transparent interaction**.

### 8.2 Components

* User Interface Layer
* Explainability Layer
* Core AI Model
* Feedback & Learning Loop

### 8.3 Human-in-the-Loop Design

* Real-time feedback capture
* Confidence calibration

---

## 9. Model Design & Training

### 9.1 Model Selection Rationale

* Interpretability vs performance trade-offs

### 9.2 Training Strategy

* Balanced datasets
* Bias detection checkpoints

### 9.3 Evaluation During Training

* Accuracy
* Stability
* Bias metrics

---

## 10. Explainability Techniques

* Feature importance
* Natural language rationales
* Example-based explanations

---

## 11. User Experience (UX) for AI

### 11.1 Human-Centered Interaction Design

* Tone & empathy
* Error handling

### 11.2 Cognitive Load Reduction

* Progressive disclosure
* Simple defaults

### 11.3 Trust Calibration

* Avoiding overconfidence
* Clear uncertainty communication

---

## 12. Evaluation Framework

### 12.1 Technical Metrics

* Accuracy
* Robustness

### 12.2 Human-Centric Metrics

* Trust scores
* Usability (SUS)
* Perceived fairness

### 12.3 User Study Design

* Task-based evaluation
* Qualitative interviews

---

## 13. Results & Findings

* Improved user trust with explanations
* Higher satisfaction with human-in-the-loop controls
* Trade-offs between transparency and speed

---

## 14. Ethical Risk Assessment

### 14.1 Identified Risks

* Automation bias
* Data leakage
* Model hallucinations

### 14.2 Mitigation Strategies

* Guardrails
* User education
* Monitoring & alerts

---

## 15. Deployment Considerations

* Continuous monitoring
* Feedback-driven updates
* Responsible scaling

---

## 16. Limitations

* Small-scale user study
* Domain-specific assumptions
* Resource constraints

---

## 17. Future Work

* Cross-cultural evaluation
* Regulatory alignment
* Longitudinal trust studies

---

## 18. Reproducibility & Open Science

* Experiment logs
* Versioned datasets
* Transparent documentation

---

## 19. Repository Structure

```text
human-centric-ai-research/
├── README.md
├── literature_review/
├── datasets/
├── models/
├── experiments/
├── evaluation/
├── ethics/
├── results/
└── docs/
```

---

## 20. Conclusion

This independent research demonstrates that **human-centric AI is not an add-on but a system-wide commitment**. Embedding human values across the AI lifecycle leads to systems that are not only effective but socially responsible and trustworthy.

---

## 21. Author

**Independent Researcher:** Tanisha Hasan
**Role:** AI Product Creator & Research-Oriented Engineer

---

## 22. License

This project is released for academic and portfolio use under an open research-friendly license.
